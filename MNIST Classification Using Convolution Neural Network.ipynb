{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Train set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape (42000, 785)\n",
      "test_set shape (28000, 784)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv('train.csv')\n",
    "test_set = pd.read_csv('test.csv')\n",
    "\n",
    "print('train_set shape', train_set.shape)\n",
    "print('test_set shape', test_set.shape)\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels shape (42000,)\n",
      "train_img shape (42000, 784)\n",
      "test set shape (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "## Extract train_set to train_imgs and train_labels\n",
    "train_labels = train_set.as_matrix()[:,0]\n",
    "train_img = train_set.as_matrix()[:,1:]\n",
    "test_img = test_set.as_matrix()[:,:]\n",
    "\n",
    "print('train_labels shape', train_labels.shape)\n",
    "print('train_img shape', train_img.shape)\n",
    "print('test set shape', test_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA/1Pp43+MfDEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c680bd0710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2,5, sharex = True, sharey = True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i in range(0,10):\n",
    "    ax[i].imshow(train_img[train_labels == i,:][30].reshape(28,28), cmap = 'Greys')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "## normalization using min max to (-1, 1)\n",
    "train_img_norm = (train_img/255 - 0.5)*2\n",
    "test_img_norm = (test_img/255 - 0.5)*2\n",
    "print(test_img_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    '''\n",
    "    This class is consist of 2 conv layers, 2 max-pooling layers, 1 dense layer and output layer.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, learning_rate = 10**-4, batchsize = 2**8, dropout_rate = 0.5, epochs = 40, l2_scale = 10**-4):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.batchsize = batchsize\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.epochs = epochs\n",
    "        self.l2_scale = l2_scale\n",
    "        \n",
    "    def build(self, X_train, Y_train):\n",
    "        \n",
    "        # build empty graph\n",
    "        m = X_train.shape[0]\n",
    "        g = tf.Graph()\n",
    "        \n",
    "        with g.as_default():\n",
    "            \n",
    "            X_train = tf.placeholder(tf.float32, shape=[None, X_train.shape[1]], name = 'X')\n",
    "            tf_y = tf.placeholder(tf.int32, shape=[None], name='Y')\n",
    "            Y_train = tf.one_hot(indices = tf.cast(tf_y, tf.int32), dtype=tf.int32, depth = 10)\n",
    "            \n",
    "            dropout_rate = tf.placeholder(tf.float32, name='dropout_rate')\n",
    "            is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "            l2_scale = tf.placeholder(tf.float32, name='l2_scale')\n",
    "            ## placeholder => 'X', 'Y', 'dropout_rate', 'is_train'\n",
    "            \n",
    "            ## Fitst conv-> max-pool layer\n",
    "            h1 = tf.layers.conv2d(tf.reshape(X_train, shape=[-1,28,28,1]), 32, (5,5), activation = tf.nn.relu,\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            h1_pool = tf.layers.max_pooling2d(h1, pool_size = (2,2), strides = (2,2))\n",
    "            \n",
    "            ## second conv-> max-pool layer\n",
    "            h2 = tf.layers.conv2d(h1_pool, 64, (5,5), activation = tf.nn.relu,\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                 kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            h2_pool = tf.layers.max_pooling2d(h2, pool_size = (2,2), strides = (2,2))\n",
    "            \n",
    "            ## dense=>dropout and output layer\n",
    "            n_shape = h2_pool.get_shape().as_list()\n",
    "            h3 = tf.layers.dense(tf.reshape(h2_pool, shape=[-1,np.prod(n_shape[1:])]),\n",
    "                                 units = 1024, activation = tf.nn.relu,\n",
    "                                kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "            h3_dropout = tf.layers.dropout(h3, rate = dropout_rate, training = is_train)\n",
    "            \n",
    "            h4 = tf.layers.dense(h3_dropout, units = 10, activation = None,\n",
    "                                kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            ## Cost and eval metrices\n",
    "            cost_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = h4, labels = Y_train), name='cost')\n",
    "            loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))/m\n",
    "            \n",
    "            cost = cost_entropy + loss\n",
    "            \n",
    "            Y_pred = tf.cast(tf.argmax(h4, axis = 1), tf.int32, 'Y_pred')\n",
    "            predictions = {'cor_pred': tf.equal(Y_pred, tf_y, name='cor_pred'),\n",
    "                           'wrong_pred': tf.logical_not(tf.equal(Y_pred, tf_y), name='wrong_pred')}\n",
    "            \n",
    "            accuracy = tf.reduce_mean(tf.cast(predictions['cor_pred'], tf.float32), name='accuracy')\n",
    "            \n",
    "            ## Optimizer \n",
    "            optimizer = tf.train.AdamOptimizer(self.learning_rate, name='train_op')\n",
    "            optimizer = optimizer.minimize(cost)\n",
    "            \n",
    "            ## saver and variable initialize\n",
    "            self.init = tf.global_variables_initializer()            \n",
    "            self.saver = tf.train.Saver()\n",
    "            \n",
    "            ## placeholder => 'X', 'Y', 'dropout_rate', 'is_train'\n",
    "            \n",
    "        self.sess = tf.Session(graph = g)\n",
    "        self.sess.run(self.init)\n",
    "        ## End build method\n",
    "        \n",
    "    def batch_generation(self, X_train, Y_train, batchsize, shuffle = True):\n",
    "        \n",
    "        m = X_train.shape[0] # num samples\n",
    "        X_temp = X_train.copy()\n",
    "        Y_temp = Y_train.copy()\n",
    "        \n",
    "        if shuffle == True:\n",
    "            \n",
    "            idx = np.arange(m)\n",
    "            np.random.shuffle(idx)\n",
    "            \n",
    "            X_temp = X_temp[idx,:]\n",
    "            Y_temp = Y_temp[idx]\n",
    "        \n",
    "        for i in range(0, m, batchsize):\n",
    "            yield(X_temp[i:i+batchsize,:], Y_temp[i:i+batchsize])\n",
    "    \n",
    "    ## End batch_generation\n",
    "    def save(self, epoch):\n",
    "        self.saver.save(self.sess, './tflayers-model/'+'CNN_model.ckpt', global_step = epoch)\n",
    "        \n",
    "    def load(self, epoch):\n",
    "        print('Loading model')\n",
    "        self.saver.restore(self.sess, './tflayers-model/'+'CNN_model.ckpt-' + str(epoch))\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        feed_dict = {'X:0':X_test, 'dropout_rate:0':1, 'is_train:0':False}\n",
    "        Y_pred = self.sess.run('Y_pred:0', feed_dict = feed_dict)\n",
    "        return Y_pred\n",
    "    \n",
    "    def train(self, X_train, Y_train, X_dev=None, Y_dev=None):\n",
    "        \n",
    "        '''\n",
    "        This method will train model of graph g\n",
    "        '''\n",
    "        self.build(X_train, Y_train)\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            batch = self.batch_generation(X_train, Y_train, self.batchsize, shuffle = True)\n",
    "            cost_avg = 0\n",
    "            train_acc_avg = 0\n",
    "            count = 0\n",
    "\n",
    "            for k, (X_batch, Y_batch) in enumerate(batch):\n",
    "                count += 1\n",
    "                ## placeholder => 'X', 'Y', 'dropout_rate', 'is_train'\n",
    "                feed_dict = {'X:0':X_batch, 'Y:0':Y_batch, 'dropout_rate:0':self.dropout_rate,\n",
    "                             'is_train:0':True, 'l2_scale:0':self.l2_scale}\n",
    "                _, train_acc, cost = self.sess.run(['train_op','accuracy:0', 'cost:0'], feed_dict = feed_dict)\n",
    "                \n",
    "                train_acc_avg += train_acc\n",
    "                cost_avg += cost\n",
    "                \n",
    "            if X_dev is not None and Y_dev is not None:\n",
    "                feed_dict = {'X:0':X_dev, 'Y:0':Y_dev, 'dropout_rate:0':1, 'is_train:0':False}\n",
    "                dev_acc = self.sess.run('accuracy:0', feed_dict = feed_dict)\n",
    "            else: dev_acc = 0\n",
    "            \n",
    "            print('Epochs : {:d} Train ACC Avg : {:.4f} Dev ACC : {:.4f} Cost Avg : {:.2f} '\n",
    "                  .format(i, train_acc_avg/count, dev_acc, cost_avg/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (39900, 784)\n",
      "X_dev shape (2100, 784)\n",
      "Y_train shape (39900,)\n",
      "Y_dev shape (2100,)\n",
      "1    0.111529\n",
      "7    0.104787\n",
      "3    0.103609\n",
      "9    0.099724\n",
      "2    0.099449\n",
      "6    0.098496\n",
      "0    0.098371\n",
      "4    0.096942\n",
      "8    0.096742\n",
      "5    0.090351\n",
      "dtype: float64\n",
      "1    0.111429\n",
      "7    0.104762\n",
      "3    0.103333\n",
      "9    0.099524\n",
      "2    0.099524\n",
      "6    0.098571\n",
      "0    0.098571\n",
      "4    0.097143\n",
      "8    0.096667\n",
      "5    0.090476\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_img_norm, train_labels, test_size = 0.05, stratify = train_labels)\n",
    "\n",
    "print('X_train shape', X_train.shape)\n",
    "print('X_dev shape', X_dev.shape)\n",
    "print('Y_train shape', Y_train.shape)\n",
    "print('Y_dev shape', Y_dev.shape)\n",
    "\n",
    "## Check stratify\n",
    "print(pd.Series(Y_train).value_counts()/len(Y_train))\n",
    "print(pd.Series(Y_dev).value_counts()/len(Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 0 Train ACC Avg : 0.7781 Dev ACC : 0.9281 Cost Avg : 0.84 \n",
      "Epochs : 1 Train ACC Avg : 0.9350 Dev ACC : 0.9567 Cost Avg : 0.22 \n",
      "Epochs : 2 Train ACC Avg : 0.9586 Dev ACC : 0.9671 Cost Avg : 0.14 \n",
      "Epochs : 3 Train ACC Avg : 0.9679 Dev ACC : 0.9743 Cost Avg : 0.11 \n",
      "Epochs : 4 Train ACC Avg : 0.9733 Dev ACC : 0.9733 Cost Avg : 0.09 \n",
      "Epochs : 5 Train ACC Avg : 0.9779 Dev ACC : 0.9786 Cost Avg : 0.07 \n",
      "Epochs : 6 Train ACC Avg : 0.9802 Dev ACC : 0.9805 Cost Avg : 0.07 \n",
      "Epochs : 7 Train ACC Avg : 0.9820 Dev ACC : 0.9795 Cost Avg : 0.06 \n",
      "Epochs : 8 Train ACC Avg : 0.9845 Dev ACC : 0.9810 Cost Avg : 0.05 \n",
      "Epochs : 9 Train ACC Avg : 0.9856 Dev ACC : 0.9819 Cost Avg : 0.05 \n",
      "Epochs : 10 Train ACC Avg : 0.9873 Dev ACC : 0.9833 Cost Avg : 0.04 \n",
      "Epochs : 11 Train ACC Avg : 0.9882 Dev ACC : 0.9852 Cost Avg : 0.04 \n",
      "Epochs : 12 Train ACC Avg : 0.9888 Dev ACC : 0.9819 Cost Avg : 0.04 \n",
      "Epochs : 13 Train ACC Avg : 0.9896 Dev ACC : 0.9852 Cost Avg : 0.03 \n",
      "Epochs : 14 Train ACC Avg : 0.9902 Dev ACC : 0.9848 Cost Avg : 0.03 \n",
      "Epochs : 15 Train ACC Avg : 0.9909 Dev ACC : 0.9871 Cost Avg : 0.03 \n",
      "Epochs : 16 Train ACC Avg : 0.9919 Dev ACC : 0.9852 Cost Avg : 0.03 \n",
      "Epochs : 17 Train ACC Avg : 0.9922 Dev ACC : 0.9876 Cost Avg : 0.03 \n",
      "Epochs : 18 Train ACC Avg : 0.9929 Dev ACC : 0.9876 Cost Avg : 0.02 \n",
      "Epochs : 19 Train ACC Avg : 0.9937 Dev ACC : 0.9862 Cost Avg : 0.02 \n",
      "Epochs : 20 Train ACC Avg : 0.9935 Dev ACC : 0.9867 Cost Avg : 0.02 \n",
      "Epochs : 21 Train ACC Avg : 0.9942 Dev ACC : 0.9876 Cost Avg : 0.02 \n",
      "Epochs : 22 Train ACC Avg : 0.9945 Dev ACC : 0.9843 Cost Avg : 0.02 \n",
      "Epochs : 23 Train ACC Avg : 0.9945 Dev ACC : 0.9867 Cost Avg : 0.02 \n",
      "Epochs : 24 Train ACC Avg : 0.9953 Dev ACC : 0.9890 Cost Avg : 0.02 \n",
      "Epochs : 25 Train ACC Avg : 0.9953 Dev ACC : 0.9857 Cost Avg : 0.02 \n",
      "Epochs : 26 Train ACC Avg : 0.9960 Dev ACC : 0.9886 Cost Avg : 0.01 \n",
      "Epochs : 27 Train ACC Avg : 0.9958 Dev ACC : 0.9881 Cost Avg : 0.01 \n",
      "Epochs : 28 Train ACC Avg : 0.9963 Dev ACC : 0.9890 Cost Avg : 0.01 \n",
      "Epochs : 29 Train ACC Avg : 0.9964 Dev ACC : 0.9876 Cost Avg : 0.01 \n",
      "Epochs : 30 Train ACC Avg : 0.9963 Dev ACC : 0.9867 Cost Avg : 0.01 \n",
      "Epochs : 31 Train ACC Avg : 0.9969 Dev ACC : 0.9886 Cost Avg : 0.01 \n",
      "Epochs : 32 Train ACC Avg : 0.9971 Dev ACC : 0.9900 Cost Avg : 0.01 \n",
      "Epochs : 33 Train ACC Avg : 0.9971 Dev ACC : 0.9886 Cost Avg : 0.01 \n",
      "Epochs : 34 Train ACC Avg : 0.9971 Dev ACC : 0.9900 Cost Avg : 0.01 \n",
      "Epochs : 35 Train ACC Avg : 0.9973 Dev ACC : 0.9886 Cost Avg : 0.01 \n",
      "Epochs : 36 Train ACC Avg : 0.9977 Dev ACC : 0.9900 Cost Avg : 0.01 \n",
      "Epochs : 37 Train ACC Avg : 0.9975 Dev ACC : 0.9905 Cost Avg : 0.01 \n",
      "Epochs : 38 Train ACC Avg : 0.9978 Dev ACC : 0.9910 Cost Avg : 0.01 \n",
      "Epochs : 39 Train ACC Avg : 0.9983 Dev ACC : 0.9876 Cost Avg : 0.01 \n",
      "Epochs : 40 Train ACC Avg : 0.9983 Dev ACC : 0.9890 Cost Avg : 0.01 \n",
      "Epochs : 41 Train ACC Avg : 0.9980 Dev ACC : 0.9886 Cost Avg : 0.01 \n",
      "Epochs : 42 Train ACC Avg : 0.9981 Dev ACC : 0.9890 Cost Avg : 0.01 \n",
      "Epochs : 43 Train ACC Avg : 0.9978 Dev ACC : 0.9900 Cost Avg : 0.01 \n",
      "Epochs : 44 Train ACC Avg : 0.9988 Dev ACC : 0.9895 Cost Avg : 0.01 \n",
      "Epochs : 45 Train ACC Avg : 0.9986 Dev ACC : 0.9895 Cost Avg : 0.01 \n",
      "Epochs : 46 Train ACC Avg : 0.9981 Dev ACC : 0.9895 Cost Avg : 0.01 \n",
      "Epochs : 47 Train ACC Avg : 0.9984 Dev ACC : 0.9895 Cost Avg : 0.01 \n",
      "Epochs : 48 Train ACC Avg : 0.9986 Dev ACC : 0.9914 Cost Avg : 0.00 \n",
      "Epochs : 49 Train ACC Avg : 0.9986 Dev ACC : 0.9905 Cost Avg : 0.00 \n",
      "Epochs : 50 Train ACC Avg : 0.9991 Dev ACC : 0.9919 Cost Avg : 0.00 \n",
      "Epochs : 51 Train ACC Avg : 0.9986 Dev ACC : 0.9905 Cost Avg : 0.00 \n",
      "Epochs : 52 Train ACC Avg : 0.9991 Dev ACC : 0.9895 Cost Avg : 0.00 \n",
      "Epochs : 53 Train ACC Avg : 0.9990 Dev ACC : 0.9910 Cost Avg : 0.00 \n",
      "Epochs : 54 Train ACC Avg : 0.9991 Dev ACC : 0.9895 Cost Avg : 0.00 \n",
      "Epochs : 55 Train ACC Avg : 0.9993 Dev ACC : 0.9900 Cost Avg : 0.00 \n",
      "Epochs : 56 Train ACC Avg : 0.9992 Dev ACC : 0.9919 Cost Avg : 0.00 \n",
      "Epochs : 57 Train ACC Avg : 0.9991 Dev ACC : 0.9905 Cost Avg : 0.00 \n",
      "Epochs : 58 Train ACC Avg : 0.9991 Dev ACC : 0.9910 Cost Avg : 0.00 \n",
      "Epochs : 59 Train ACC Avg : 0.9993 Dev ACC : 0.9895 Cost Avg : 0.00 \n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "cnn = CNN(epochs = epochs, l2_scale = 10**-3)\n",
    "cnn.train(X_train, Y_train, X_dev, Y_dev)\n",
    "cnn.save(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000,)\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred = cnn.predict(test_img_norm)\n",
    "print(Y_test_pred.shape)\n",
    "Y_test_pred_pandas = pd.DataFrame(Y_test_pred)\n",
    "Y_test_pred_pandas.to_csv('Output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "INFO:tensorflow:Restoring parameters from ./tflayers-model/CNN_model.ckpt-20\n"
     ]
    }
   ],
   "source": [
    "cnn.load(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
